{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Classification of MNIST Dataset Using Convolutional Neural Networks (CNN)\n\nThis notebook delves into a classification task involving the use of Convolutional Neural Networks (CNNs) on the famous MNIST dataset, available at [Yann LeCun's website](http://yann.lecun.com/exdb/mnist/).\n\nWe have structured the notebook into two main sections:\n\n## Objectives\nThis section delineates the specific goals of this notebook, which are:\n\n- Training a Deep Neural Network (DNN) model to achieve high accuracy in recognizing handwritten digits.\n\n## Implementation\nThis section presents the hands-on steps necessary to attain the previously mentioned objectives. These steps include:\n\n1. **Imports, Constants, and Methods:** Setting up the necessary libraries, constants, and methods for our task.\n2. **Data Retrieval:** Acquiring the MNIST dataset to be used for training and testing purposes.\n3. **Data Preparation:** Preprocessing and setting up the dataset to facilitate effective training of the CNN model.\n4. **Model Creation:** Architecting and constructing the CNN model utilizing Keras.\n5. **Model Training:** Engaging the CNN model in learning using the prepared dataset.\n6. **Evaluation:** Gauging the trained model's performance and analyzing the classification results.","metadata":{}},{"cell_type":"markdown","source":"## 1. Imports & Constants & Methods","metadata":{}},{"cell_type":"markdown","source":"### 1.1 - Imports","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport sys,os\n\nfrom importlib import reload\n\nimport math\nimport sklearn.metrics\nimport itertools\nfrom sklearn.preprocessing import MinMaxScaler\n\n!pip install visualkeras\n\nimport visualkeras","metadata":{"execution":{"iopub.status.busy":"2023-07-15T15:52:53.587797Z","iopub.execute_input":"2023-07-15T15:52:53.588191Z","iopub.status.idle":"2023-07-15T15:53:15.242082Z","shell.execute_reply.started":"2023-07-15T15:52:53.588160Z","shell.execute_reply":"2023-07-15T15:53:15.240650Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.2 Constants","metadata":{}},{"cell_type":"markdown","source":"Verbosity during training:\n- 0: Silent mode, no output will be displayed during training.\n- 1: Progress bar mode, a progress bar will be displayed to show the progress of each epoch.\n- 2: One line per epoch mode, a concise summary will be displayed for each epoch.\n\nFor the current training configuration:\n- Batch size: 512, which determines the number of samples processed in each training iteration.\n- Number of epochs: 16, indicating the total number of times the model will be trained on the entire dataset.\n","metadata":{}},{"cell_type":"code","source":"fit_verbosity = 1\n\nbatch_size  = 512\nepochs      =  16","metadata":{"execution":{"iopub.status.busy":"2023-07-15T15:53:15.244517Z","iopub.execute_input":"2023-07-15T15:53:15.245337Z","iopub.status.idle":"2023-07-15T15:53:15.251561Z","shell.execute_reply.started":"2023-07-15T15:53:15.245310Z","shell.execute_reply":"2023-07-15T15:53:15.249874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.3 Methods","metadata":{}},{"cell_type":"code","source":"def show_images(\n    images, \n    labels=None, \n    indices='all', \n    columns=12, \n    figure_size=(1, 1),                \n    show_colorbar=False, \n    y_pred=None, \n    color_map='binary',\n    normalization=None, \n    padding=0.35, \n    spines_alpha=1, \n    font_size=20,\n    interpolation='lanczos'\n):\n    \"\"\"\n    Show a grid of images with labels.\n\n    Args:\n        images: The images to display. Shapes must be (-1, lx, ly), (-1, lx, ly, 1), or (-1, lx, ly, 3).\n        labels: Real classes or labels associated with the images. (None)\n        indices: Indices of images to show or 'all' for all images. ('all')\n        columns: Number of columns in the grid. (12)\n        figure_size: Size of the figure (width, height). (1, 1)\n        show_colorbar: Whether to show the colorbar. (False)\n        predicted_labels: Predicted classes associated with the images. (None)\n        color_map: Matplotlib color map to use. ('binary')\n        normalization: Matplotlib imshow normalization. (None)\n        padding: Padding between rows in the grid. (0.35)\n        spines_alpha: Alpha value for the spines. (1)\n        font_size: Font size in pixels. (20)\n        interpolation: Interpolation method for displaying the images. ('lanczos')\n\n    Returns:\n        None\n    \"\"\"\n    if indices == 'all':\n        indices = range(len(images))\n\n    if normalization and len(normalization) == 2:\n        normalization = matplotlib.colors.Normalize(vmin=normalization[0], vmax=normalization[1])\n\n    draw_labels = (labels is not None)\n    draw_predicted_labels = (y_pred is not None)\n\n    rows = math.ceil(len(indices) / columns)\n    fig = plt.figure(figsize=(columns * figure_size[0], rows * (figure_size[1] + padding)))\n\n    n = 1\n    for i in indices:\n        axs = fig.add_subplot(rows, columns, n)\n        n += 1\n\n        # ---- Shape is (lx,ly)\n        if len(images[i].shape) == 2:\n            xx = images[i]\n        # ---- Shape is (lx,ly,n)\n        if len(images[i].shape) == 3:\n            (lx, ly, lz) = images[i].shape\n            if lz == 1:\n                xx = images[i].reshape(lx, ly)\n            else:\n                xx = images[i]\n\n        img = axs.imshow(xx, cmap=color_map, norm=normalization, interpolation=interpolation)\n\n        axs.spines['right'].set_visible(True)\n        axs.spines['left'].set_visible(True)\n        axs.spines['top'].set_visible(True)\n        axs.spines['bottom'].set_visible(True)\n\n        axs.spines['right'].set_alpha(spines_alpha)\n        axs.spines['left'].set_alpha(spines_alpha)\n        axs.spines['top'].set_alpha(spines_alpha)\n        axs.spines['bottom'].set_alpha(spines_alpha)\n\n        axs.set_yticks([])\n        axs.set_xticks([])\n\n        if draw_labels and not draw_predicted_labels:\n            axs.set_xlabel(labels[i], fontsize=font_size)\n        if draw_labels and draw_predicted_labels:\n            if labels[i] != y_pred[i]:\n                axs.set_xlabel(f'{y_pred[i]} ({labels[i]})', fontsize=font_size)\n                axs.xaxis.label.set_color('red')\n            else:\n                axs.set_xlabel(labels[i], fontsize=font_size)\n\n        if show_colorbar:\n            fig.colorbar(img, orientation=\"vertical\", shrink=0.65)\n\n    plt.show()\n\n    \ndef show_history(\n    history, \n    figsize=(8,6), \n    plot={\"Accuracy\":['accuracy','val_accuracy'], 'Loss':['loss', 'val_loss']}\n):\n    \"\"\"\n    Show history\n    args:\n        history: history\n        figsize: fig size\n        plot: list of data to plot : {<title>:[<metrics>,...], ...}\n    \"\"\"\n    fig_id=0\n    for title,curves in plot.items():\n        plt.figure(figsize=figsize)\n        plt.title(title)\n        plt.ylabel(title)\n        plt.xlabel('Epoch')\n        for c in curves:\n            plt.plot(history.history[c])\n        plt.legend(curves, loc='upper left')\n        plt.show()\n        \n        \ndef show_confusion_matrix(\n    y_true,\n    y_pred,\n    target_names,\n    title='Confusion matrix',\n    cmap=None,\n    normalize=True,\n    figsize=(10, 8),\n    digit_format='{:0.2f}'\n):\n    cm = sklearn.metrics.confusion_matrix( y_true,y_pred, normalize=None, labels=target_names)\n    \n    accuracy = np.trace(cm) / float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=figsize)\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=90)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n\n    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, digit_format.format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n    plt.show()\n        ","metadata":{"execution":{"iopub.status.busy":"2023-07-15T15:53:15.253486Z","iopub.execute_input":"2023-07-15T15:53:15.254072Z","iopub.status.idle":"2023-07-15T15:53:15.279088Z","shell.execute_reply.started":"2023-07-15T15:53:15.254037Z","shell.execute_reply":"2023-07-15T15:53:15.277540Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Retrieve data\nMNIST is one of the most famous historic dataset.  \nInclude in [Keras datasets](https://www.tensorflow.org/api_docs/python/tf/keras/datasets)","metadata":{}},{"cell_type":"code","source":"(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n\nx_train = x_train.reshape(-1, 28, 28, 1)\nx_test = x_test.reshape(-1, 28, 28, 1)\n\nprint(\"x_train shape:\", x_train.shape)\nprint(\"y_train shape:\", y_train.shape)\nprint(\"x_test shape:\", x_test.shape)\nprint(\"y_test shape:\", y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-07-15T15:53:15.280705Z","iopub.execute_input":"2023-07-15T15:53:15.281125Z","iopub.status.idle":"2023-07-15T15:53:15.635512Z","shell.execute_reply.started":"2023-07-15T15:53:15.281100Z","shell.execute_reply":"2023-07-15T15:53:15.634409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Preparing the data","metadata":{}},{"cell_type":"code","source":"print('Before normalization : Min={}, max={}'.format(x_train.min(),x_train.max()))\n\nscaler = MinMaxScaler()\nx_train = scaler.fit_transform(x_train.reshape(-1, 1)).reshape(x_train.shape)\nx_test = scaler.transform(x_test.reshape(-1, 1)).reshape(x_test.shape)\n\nprint('After normalization : Min={}, max={}'.format(x_train.min(), x_test.max()))","metadata":{"execution":{"iopub.status.busy":"2023-07-15T15:53:15.637841Z","iopub.execute_input":"2023-07-15T15:53:15.638115Z","iopub.status.idle":"2023-07-15T15:53:15.945710Z","shell.execute_reply.started":"2023-07-15T15:53:15.638090Z","shell.execute_reply":"2023-07-15T15:53:15.945059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_images(x_train, y_train, [9], figure_size = (5,5 ), show_colorbar=True)\nshow_images(x_train, y_train, range(50,100), columns=10)","metadata":{"execution":{"iopub.status.busy":"2023-07-15T15:53:15.947191Z","iopub.execute_input":"2023-07-15T15:53:15.947548Z","iopub.status.idle":"2023-07-15T15:53:18.297995Z","shell.execute_reply.started":"2023-07-15T15:53:15.947516Z","shell.execute_reply":"2023-07-15T15:53:18.296702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Create model\n\nInformation about:\n- [Optimizer](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers): Determines how the model is updated based on the gradients computed during training.\n- [Activation](https://www.tensorflow.org/api_docs/python/tf/keras/activations): Determines the shape of the output from a neural network layer. It adds non-linearity to the model.\n- [Loss](https://www.tensorflow.org/api_docs/python/tf/keras/losses): Measures how different the model's predictions are from the target values. It is used to guide the model's optimization.\n- [Metrics](https://www.tensorflow.org/api_docs/python/tf/keras/metrics): Measures used to evaluate the performance of the model, such as accuracy, precision, recall, etc.","metadata":{}},{"cell_type":"code","source":"model = keras.models.Sequential()\n\nmodel.add( keras.layers.Input((28,28,1)) )\n\nmodel.add( keras.layers.Conv2D(8, (3,3),  activation='relu') )\nmodel.add( keras.layers.MaxPooling2D((2,2)))\nmodel.add( keras.layers.Dropout(0.2))\n\nmodel.add( keras.layers.Conv2D(16, (3,3), activation='relu') )\nmodel.add( keras.layers.MaxPooling2D((2,2)))\nmodel.add( keras.layers.Dropout(0.2))\n\nmodel.add( keras.layers.Flatten()) \nmodel.add( keras.layers.Dense(100, activation='relu'))\nmodel.add( keras.layers.Dropout(0.5))\n\nmodel.add( keras.layers.Dense(10, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2023-07-15T15:53:18.299282Z","iopub.execute_input":"2023-07-15T15:53:18.299862Z","iopub.status.idle":"2023-07-15T15:53:18.517091Z","shell.execute_reply.started":"2023-07-15T15:53:18.299835Z","shell.execute_reply":"2023-07-15T15:53:18.515531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualkeras.layered_view(model, legend=True, scale_z=1, scale_xy =20, spacing=80)","metadata":{"execution":{"iopub.status.busy":"2023-07-15T15:53:18.518746Z","iopub.execute_input":"2023-07-15T15:53:18.519107Z","iopub.status.idle":"2023-07-15T15:53:18.625936Z","shell.execute_reply.started":"2023-07-15T15:53:18.519079Z","shell.execute_reply":"2023-07-15T15:53:18.624683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()\n\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-07-15T15:53:18.627392Z","iopub.execute_input":"2023-07-15T15:53:18.627895Z","iopub.status.idle":"2023-07-15T15:53:18.665590Z","shell.execute_reply.started":"2023-07-15T15:53:18.627871Z","shell.execute_reply":"2023-07-15T15:53:18.664669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Train the model","metadata":{}},{"cell_type":"code","source":"history = model.fit(  x_train, y_train,\n                      batch_size      = batch_size,\n                      epochs          = epochs,\n                      verbose         = fit_verbosity,\n                      validation_data = (x_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2023-07-15T15:53:18.666754Z","iopub.execute_input":"2023-07-15T15:53:18.667025Z","iopub.status.idle":"2023-07-15T15:55:32.903097Z","shell.execute_reply.started":"2023-07-15T15:53:18.667004Z","shell.execute_reply":"2023-07-15T15:55:32.901455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. Evaluate\n### 6.1. Final loss and accuracy\nNote : With a DNN, we had a precision of the order of : 97.7%","metadata":{}},{"cell_type":"code","source":"score = model.evaluate(x_test, y_test, verbose=0)\n\nprint(f'Test loss     : {score[0]:4.4f}')\nprint(f'Test accuracy : {score[1]:4.4f}')","metadata":{"execution":{"iopub.status.busy":"2023-07-15T15:55:32.905056Z","iopub.execute_input":"2023-07-15T15:55:32.905480Z","iopub.status.idle":"2023-07-15T15:55:35.521357Z","shell.execute_reply.started":"2023-07-15T15:55:32.905443Z","shell.execute_reply":"2023-07-15T15:55:35.519893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6.2. Plot history","metadata":{}},{"cell_type":"code","source":"show_history(history, figsize=(6,4))","metadata":{"execution":{"iopub.status.busy":"2023-07-15T15:55:35.523718Z","iopub.execute_input":"2023-07-15T15:55:35.524079Z","iopub.status.idle":"2023-07-15T15:55:36.010583Z","shell.execute_reply.started":"2023-07-15T15:55:35.524053Z","shell.execute_reply":"2023-07-15T15:55:36.009490Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6.3. Plot results","metadata":{}},{"cell_type":"code","source":"y_probabilities = model.predict(x_test)\ny_pred    = np.argmax(y_probabilities, axis=-1)\n\n\nshow_images(x_test, y_test, range(0,200), columns=12, figure_size = (1,1), y_pred=y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-07-15T15:55:36.011882Z","iopub.execute_input":"2023-07-15T15:55:36.012207Z","iopub.status.idle":"2023-07-15T15:55:45.768531Z","shell.execute_reply.started":"2023-07-15T15:55:36.012181Z","shell.execute_reply":"2023-07-15T15:55:45.767315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6.4. Plot some errors","metadata":{}},{"cell_type":"code","source":"errors=[ i for i in range(len(x_test)) if y_pred[i]!=y_test[i] ]\nerrors=errors[:min(24,len(errors))]\nshow_images(x_test, y_test, errors[:15], columns=6, figure_size = (2,2), y_pred=y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-07-15T15:55:45.771468Z","iopub.execute_input":"2023-07-15T15:55:45.773286Z","iopub.status.idle":"2023-07-15T15:55:46.569118Z","shell.execute_reply.started":"2023-07-15T15:55:45.773256Z","shell.execute_reply":"2023-07-15T15:55:46.567813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6.5. Confusion Matrix","metadata":{}},{"cell_type":"code","source":"show_confusion_matrix(y_test,y_pred,range(10),normalize=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-15T15:55:46.570563Z","iopub.execute_input":"2023-07-15T15:55:46.570921Z","iopub.status.idle":"2023-07-15T15:55:47.072608Z","shell.execute_reply.started":"2023-07-15T15:55:46.570884Z","shell.execute_reply":"2023-07-15T15:55:47.071057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## References\n\nThe creation of this document was greatly influenced by the following key sources of information:\n\n1. [Yann LeCun's website](http://yann.lecun.com/exdb/mnist/) - This is the official site for the MNIST dataset, providing crucial details about the data structure and its applications.\n2. [Keras Datasets](https://www.tensorflow.org/api_docs/python/tf/keras/datasets) - An invaluable resource for accessing and understanding various Keras datasets, including MNIST.\n3. [Fidle](https://gricad-gitlab.univ-grenoble-alpes.fr/talks/fidle/-/wikis/home) - An informative guide that provides in-depth explanations and examples on various data science topics.","metadata":{}}]}